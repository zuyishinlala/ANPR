{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics==8.0.196\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNFkSJe0EdZZ",
        "outputId": "e28ce350-a6d4-47f4-ba51-818caf79862a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 30.0/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "CKVWR5X6LzzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/data1.zip -d ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EGiQ5YWEQzz",
        "outputId": "b0aba2bf-55e2-4050-c42d-55cb40077bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/data1.zip\n",
            "   creating: ./data1/\n",
            "  inflating: ./data1/001.mp4         \n",
            "  inflating: ./data1/002.mp4         \n",
            "  inflating: ./data1/003.mp4         \n",
            "  inflating: ./data1/004.mp4         \n",
            "  inflating: ./data1/005.mp4         \n",
            "  inflating: ./data1/006.mp4         \n",
            "  inflating: ./data1/007.mp4         \n",
            "  inflating: ./data1/008.mp4         \n",
            "  inflating: ./data1/009.mp4         \n",
            "  inflating: ./data1/010.mp4         \n",
            "  inflating: ./data1/011.mp4         \n",
            "  inflating: ./data1/012.mp4         \n",
            "  inflating: ./data1/013.mp4         \n",
            "  inflating: ./data1/014.mp4         \n",
            "  inflating: ./data1/015.mp4         \n",
            "  inflating: ./data1/016.mp4         \n",
            "  inflating: ./data1/017.mp4         \n",
            "  inflating: ./data1/018.mp4         \n",
            "  inflating: ./data1/019.mp4         \n",
            "  inflating: ./data1/020.mp4         \n",
            "  inflating: ./data1/021.mp4         \n",
            "  inflating: ./data1/022.mp4         \n",
            "  inflating: ./data1/023.mp4         \n",
            "  inflating: ./data1/024.mp4         \n",
            "  inflating: ./data1/025.mp4         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install easyocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW3PUxQvb3l8",
        "outputId": "c4db705d-6000-43c8-81e0-074f5416910c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.18.0+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.82)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.3)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.4)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->easyocr) (12.5.40)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi->easyocr) (1.16.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.5.22)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n",
            "Installing collected packages: pyclipper, ninja, python-bidi, easyocr\n",
            "Successfully installed easyocr-1.7.1 ninja-1.11.1.1 pyclipper-1.3.0.post5 python-bidi-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import easyocr\n",
        "reader = easyocr.Reader(['en'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLr_OkiuIEHS",
        "outputId": "b98ccfae-8f55-44c4-aa2b-c2db6b217116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model from local\n",
        "Model_Name = \"./best.pt\"\n",
        "Best_Model = YOLO(Model_Name)"
      ],
      "metadata": {
        "id": "IBuVbVeN8GyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frames(input_video_path, output_video_path):\n",
        "    '''\n",
        "    Shrink Video size by 2 to improve compute time\n",
        "    '''\n",
        "\n",
        "    # Open the input video\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open video.\")\n",
        "        return\n",
        "\n",
        "    # Get video properties\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Define the codec and create VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "    frame_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Extract every second frame\n",
        "        if frame_count % 10 == 0:\n",
        "            out.write(frame)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    # Release everything when the job is finished\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    print(f\"New video created: {output_video_path}\")"
      ],
      "metadata": {
        "id": "tlFcKxj_cSc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_mp4_files(directory):\n",
        "    '''\n",
        "    Obtain file name from directory\n",
        "    ret : .mp4 file names (list)\n",
        "    '''\n",
        "    mp4_files = []\n",
        "\n",
        "    video_basename = []\n",
        "\n",
        "    for file in os.listdir(directory):\n",
        "        if file.endswith(\".mp4\"):\n",
        "\n",
        "            mp4_files.append(os.path.join(directory, file))\n",
        "\n",
        "            video_basename.append(os.path.splitext(file)[0])\n",
        "\n",
        "    return mp4_files, video_basename"
      ],
      "metadata": {
        "id": "mPbMo6iL7ZuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = YOLO(\"yolov8n.pt\")\n",
        "# result = model.track(\"/content/videos/002.mp4\", conf = 0.3, iou = 0.5, save = True, name='off_test_result')\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "zip_file_path = './videos.zip'\n",
        "\n",
        "extract_to_directory = './'\n",
        "\n",
        "def unzip_file(zip_file_path, extract_to):\n",
        "    \"\"\"\n",
        "    Unzip a file to a specified directory.\n",
        "\n",
        "    Parameters:\n",
        "        zip_file_path (str): Path to the zip file.\n",
        "        extract_to (str): Directory where the contents of the zip file will be extracted.\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "# Make sure the extraction directory exists\n",
        "if not os.path.exists(extract_to_directory):\n",
        "    os.makedirs(extract_to_directory)\n",
        "\n",
        "# Unzip the file\n",
        "unzip_file(zip_file_path, extract_to_directory)"
      ],
      "metadata": {
        "id": "OcYx01iWGbKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_video_folder_name = 'videos_new' # a directory folder to store processed video\n",
        "\n",
        "if not os.path.exists(processed_video_folder_name):\n",
        "   os.makedirs(processed_video_folder_name)\n",
        "\n",
        "video_folder_name = 'data1' # directory that stores mp4 files\n",
        "\n",
        "save_txt_path = './410985034.txt'\n",
        "\n",
        "video_names, video_basenames = list_mp4_files(video_folder_name)\n",
        "\n",
        "\n",
        "# Processed Videos shrink frames video by 2\n",
        "for video, basename in zip(video_names, video_basenames):\n",
        "    extract_frames(video, f'{processed_video_folder_name}/{basename}.mp4')"
      ],
      "metadata": {
        "id": "I10SvMIjutAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_images_from_video(video_path, crops):\n",
        "\n",
        "    '''\n",
        "    cropped detect bounding box\n",
        "    ret : ROI images(list)\n",
        "    '''\n",
        "\n",
        "    cropped_images = []\n",
        "\n",
        "    # Open the video\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open video.\")\n",
        "        return cropped_images\n",
        "\n",
        "    frame_count = 0\n",
        "    crop_index = 0\n",
        "    crop_length = len(crops)\n",
        "\n",
        "    while cap.isOpened() and crop_index < crop_length:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Check if the current frame should be cropped\n",
        "        while crop_index < crop_length and frame_count == crops[crop_index][2]:\n",
        "\n",
        "            x1, y1, x2, y2 = [int(value) for value in crops[crop_index][3]]\n",
        "\n",
        "            cropped_frame = frame[y1 : y2, x1 : x2]\n",
        "\n",
        "            cropped_images.append(cropped_frame)\n",
        "\n",
        "            crop_index += 1\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    return cropped_images"
      ],
      "metadata": {
        "id": "rmisYWHCD2eB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_line_ransac(x, y, num_iterations=1000, threshold= 0.2):\n",
        "    print(f\"Number of masks: {len(x)}\")\n",
        "    assert(len(x) == len(y)), \"length of input x, y is not equal.\"\n",
        "    best_model = None\n",
        "    best_inliers = []\n",
        "    best_error = np.inf\n",
        "\n",
        "    picked_size = max(min(len(x) // 2, 6), 1)\n",
        "\n",
        "    for _ in range(num_iterations):\n",
        "        # Randomly select 2 points\n",
        "        indices = np.random.choice(len(x), picked_size, replace=False)\n",
        "\n",
        "        x_sample = x[indices]\n",
        "        y_sample = y[indices]\n",
        "\n",
        "        # Fit a line to the selected points\n",
        "        model = LinearRegression()\n",
        "        model.fit(x_sample.reshape(-1, 1), y_sample)\n",
        "\n",
        "        # Calculate distances from all points to the line\n",
        "        distances = np.abs(model.predict(x.reshape(-1, 1)) - y)\n",
        "\n",
        "        # Count inliers (points within threshold distance to the line)\n",
        "        inliers = np.where(distances < threshold)[0]\n",
        "\n",
        "        if(len(inliers)) > 0:\n",
        "          # Calculate error (mean squared error of inliers)\n",
        "          # error = mean_squared_error(y[inliers], model.predict(x[inliers].reshape(-1, 1)))\n",
        "\n",
        "          error = sum(distances[inliers])\n",
        "\n",
        "          # Update best model if this model has lower error and more inliers\n",
        "          if len(inliers) > len(best_inliers) or (len(inliers) == len(best_inliers) and error < best_error):\n",
        "              best_model = model\n",
        "              best_inliers = inliers\n",
        "              best_error = error\n",
        "\n",
        "    return best_model, best_inliers"
      ],
      "metadata": {
        "id": "DNMxtFwzvJ0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Extract_good_detections(result):\n",
        "    '''\n",
        "    ret : map\n",
        "    '''\n",
        "    # record good frames & detections\n",
        "\n",
        "    appeared_id = {}\n",
        "    for idx, r in enumerate(result):\n",
        "\n",
        "        boxes = r.boxes  # Boxes object for bbox outputs\n",
        "\n",
        "        # classes = r.cls\n",
        "        probs = r.probs  # Class probabilities for classification outputs\n",
        "\n",
        "        if boxes.cls.numel() != 0: # Prediction Not NULL\n",
        "\n",
        "            for box in boxes:\n",
        "\n",
        "              if box.id is not None:\n",
        "\n",
        "                id = int(box.id[0])\n",
        "                xyxy = box.xyxy[0]\n",
        "                cls = int(box.cls[0])\n",
        "                conf = float(box.conf)\n",
        "\n",
        "                width, height = xyxy[2] - xyxy[0], xyxy[3] - xyxy[1]\n",
        "                ratio = width / height\n",
        "\n",
        "                value = {'conf': conf, 'cls': cls, 'idx' : idx, 'box' : xyxy}\n",
        "\n",
        "                if 1.2 < ratio and ratio < 6 and width > 80 and height > 10:\n",
        "\n",
        "                  if id in appeared_id:\n",
        "\n",
        "                    if conf > appeared_id[id]['conf']:\n",
        "\n",
        "                      appeared_id[id] = value\n",
        "                  else:\n",
        "                    appeared_id[id] = value\n",
        "\n",
        "    return appeared_id"
      ],
      "metadata": {
        "id": "KcAGh_YT7ERj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_license(cropped_images):\n",
        "\n",
        "    # List to store extracted text from each image\n",
        "    extracted_texts = []\n",
        "\n",
        "    # Iterate over each image in the list\n",
        "    for img in cropped_images:\n",
        "\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        height, width = img.shape[0:2]\n",
        "\n",
        "        # width, height = gray.size\n",
        "        # # # histogram equalization\n",
        "        # equ = cv2.equalizeHist(gray)\n",
        "\n",
        "        # blurred = cv2.GaussianBlur(equ, (5, 5), 0)\n",
        "\n",
        "        # cv2_imshow(blurred)\n",
        "\n",
        "        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "        cv2_imshow(binary)\n",
        "\n",
        "        # Find contours in the binary mask\n",
        "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        x_coord = []\n",
        "        y_coord = []\n",
        "\n",
        "        # # Loop over the contours\n",
        "        for contour in contours:\n",
        "\n",
        "            # Calculate the bounding rectangle for each contour\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "            if ((w / width < 0.5) and (h / height < 0.8)):\n",
        "              # cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
        "              x_coord.append((x + (w //2)) / width)\n",
        "              y_coord.append((y + (h //2)) / height)\n",
        "\n",
        "        if(len(x_coord) == 0):\n",
        "           # Use pytesseract to do OCR on the image\n",
        "          result = reader.readtext(binary)\n",
        "\n",
        "          for (bbox, text, prob) in result:\n",
        "\n",
        "            if len(text) >= 3:\n",
        "              extracted_texts.append(text)\n",
        "\n",
        "        else:\n",
        "          x_coord, y_coord = np.array(x_coord), np.array(y_coord)\n",
        "\n",
        "          best_Model, best_inliers = fit_line_ransac(x_coord, y_coord, 50, 0.05)\n",
        "\n",
        "          min_x, min_y, max_x, max_y = width, height, 0, 0\n",
        "\n",
        "          for idx in best_inliers:\n",
        "\n",
        "              contour = contours[idx]\n",
        "\n",
        "              # Calculate the bounding rectangle for each contour\n",
        "              x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "              min_x = min(min_x, x)\n",
        "              min_y = min(min_y, y)\n",
        "              max_x = max(max_x, x + w)\n",
        "              max_y = max(max_y, y + h)\n",
        "\n",
        "          min_x = max(0, min_x)\n",
        "          min_y = max(0, min_y)\n",
        "          max_x = min(width, max_x)\n",
        "          max_y = min(height, max_y)\n",
        "\n",
        "          if len(best_inliers) < 2:\n",
        "            license_plate = binary\n",
        "          else:fAH\n",
        "            license_plate = img[min_y:max_y, min_x:max_x]\n",
        "\n",
        "          cv2_imshow(license_plate)\n",
        "\n",
        "          clahe = cv2.createCLAHE()\n",
        "          license_plate = clahe.apply(license_plate)\n",
        "\n",
        "          # Use pytesseract to do OCR on the image\n",
        "          result = reader.readtext(license_plate)\n",
        "\n",
        "          for (bbox, text, prob) in result:\n",
        "\n",
        "            if len(text) >= 4:\n",
        "              extracted_texts.append(text)\n",
        "\n",
        "        # Append the extracted text to the list\n",
        "\n",
        "    return extracted_texts"
      ],
      "metadata": {
        "id": "7_ZEa-YqzAaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "license_list = []\n",
        "\n",
        "for basename in video_basenames:\n",
        "\n",
        "  video_directory = f'{processed_video_folder_name}/{basename}.mp4'\n",
        "\n",
        "  print('================================')\n",
        "  print(f'reading video:{video_directory}')\n",
        "  print('================================')\n",
        "\n",
        "  # Obtain predicted results on processed Videos\n",
        "  results = Best_Model.track( video_directory, conf = 0.3, iou = 0.5, name='test_result')\n",
        "\n",
        "  appeared_id = Extract_good_detections(results)\n",
        "\n",
        "  assert isinstance(appeared_id, dict), \"'appeared_id' is not a dictionary (map)\"\n",
        "\n",
        "  ordered_frame = [(v['conf'], v['cls'], v['idx'], v['box']) for v in sorted(appeared_id.values(), key=lambda x: x['idx'])]\n",
        "\n",
        "  print('================================')\n",
        "\n",
        "  print(f'Get {len(ordered_frame)} Detections')\n",
        "  print(ordered_frame)\n",
        "\n",
        "  print('================================')\n",
        "\n",
        "  # # Cropped images\n",
        "  cropped_images = crop_images_from_video(video_directory, ordered_frame)\n",
        "\n",
        "  extract_texts = get_license(cropped_images)\n",
        "\n",
        "  print(f'License plate is: {extract_texts}')\n",
        "\n",
        "  # cv2_imshow(cropped_images[0])\n",
        "  license_list.append(extract_texts)"
      ],
      "metadata": {
        "id": "oUrliqPuH8-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the file exists and delete it if it does\n",
        "if os.path.exists(save_txt_path):\n",
        "        os.remove(save_txt_path)\n",
        "\n",
        "for license, basename in zip(license_list, video_basenames):\n",
        "\n",
        "   joined_license = ' '.join(license)\n",
        "\n",
        "   with open(save_txt_path, 'a') as file:\n",
        "\n",
        "        file.write(f'{basename} ')\n",
        "        # Write the joined text to the file\n",
        "        file.write(joined_license + '\\n')"
      ],
      "metadata": {
        "id": "YWcADqEMiEHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the file\n",
        "files.download(save_txt_path)"
      ],
      "metadata": {
        "id": "r5T15jRT41o5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3d757fa9-0098-4b0b-cf7d-8868ede9d9e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_542b0da1-cd34-42bf-9111-d33130ed05d0\", \"410985034.txt\", 310)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    }
  ]
}